{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa262ff2",
   "metadata": {},
   "source": [
    "# Week 8 Assignment - High Frequency Words\n",
    "\n",
    "**By Eddie Xu and Mohamed Hassan-El Serafi**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e469cef5",
   "metadata": {},
   "source": [
    "Please answer the following questions in an IPython Notebook, posted to GitHub.\n",
    "1. Choose a corpus of interest.\n",
    "2. How many total unique words are in the corpus? (Please feel free to define unique words in any interesting,\n",
    "defensible way).\n",
    "3. Taking the most common words, how many unique words represent half of the total words in the corpus?\n",
    "4. Identify the 200 highest frequency words in this corpus.\n",
    "5. Create a graph that shows the relative frequency of these 200 words.\n",
    "6. Does the observed relative frequency of these words follow Zipf’s law? Explain.\n",
    "7. In what ways do you think the frequency of the words in this corpus differ from “all words in all corpora.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c167ed7",
   "metadata": {},
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "730ff66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddiexuexia/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/eddiexuexia/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# download nltk corpus (first time only)\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef5d50d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "# libraries used\n",
    "# %pip install wordcloud\n",
    "import nltk\n",
    "from nltk.book import *\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554a8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cfc782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a663c2a5",
   "metadata": {},
   "source": [
    "## Unique Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba318ba3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gen_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gen \u001b[38;5;241m=\u001b[39m [w\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgen_all\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m w\u001b[38;5;241m.\u001b[39misalpha() \u001b[38;5;129;01mand\u001b[39;00m w\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)] \u001b[38;5;66;03m#remove special characters and numbers\u001b[39;00m\n\u001b[1;32m      2\u001b[0m total_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(gen)  \u001b[38;5;66;03m#get a raw count of significant words in the text\u001b[39;00m\n\u001b[1;32m      3\u001b[0m gen_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(gen) \u001b[38;5;66;03m#creates one copy of each unique word\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gen_all' is not defined"
     ]
    }
   ],
   "source": [
    "gen = [w.lower() for w in gen_all if w.isalpha() and w.lower() not in stopwords.words('english')] #remove special characters and numbers\n",
    "total_words = len(gen)  #get a raw count of significant words in the text\n",
    "gen_set = set(gen) #creates one copy of each unique word\n",
    "len(gen_set), total_words  #counts number of unique words vs total words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1540e2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea6c3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ec2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8afa2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8286ccb2",
   "metadata": {},
   "source": [
    "## Taking the most common words, how many unique words represent half of the total words in the corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8532553f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fdist \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mFreqDist([word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgen\u001b[49m]) \u001b[38;5;66;03m#counts how many times each word occurs in text\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(fdist\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;28mlen\u001b[39m(gen_set)),columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcounts\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m#create a dataframe of the top 2000 words\u001b[39;00m\n\u001b[1;32m      4\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gen' is not defined"
     ]
    }
   ],
   "source": [
    "fdist = nltk.FreqDist([word for word in gen]) #counts how many times each word occurs in text\n",
    "df = pd.DataFrame(fdist.most_common(len(gen_set)),columns=['word','counts'])  #create a dataframe of the top 2000 words\n",
    "\n",
    "words = 0\n",
    "distinct_count = 0\n",
    "for i in range(len(df)):\n",
    "    #print(df.iloc[i,0], df.iloc[i,1])\n",
    "    words += df.iloc[i, 1]\n",
    "    distinct_count = i\n",
    "    if words > total_words/2:\n",
    "        break\n",
    "\n",
    "print(i, words, total_words) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16ad7ba",
   "metadata": {},
   "source": [
    "## 200 Highest Frequency Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d34265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e073aeb",
   "metadata": {},
   "source": [
    "## Graph of Relative Frequency for 200 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7446fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fef0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6395eac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
