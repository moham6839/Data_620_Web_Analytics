{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b05d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "\n",
    "\n",
    "# Assuming your dataset is stored in a pandas DataFrame called 'df'\n",
    "\n",
    "\n",
    "\n",
    "# Extract values from the four variables\n",
    "\n",
    "var1_values = df['gender'].tolist()\n",
    "\n",
    "var2_values = df['cardio'].tolist()\n",
    "\n",
    "var3_values = df['height'].tolist()\n",
    "\n",
    "var4_values = df['weight'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "# Create a list of tuples where each tuple represents a node\n",
    "\n",
    "nodes = [(v1, v2, v3, v4) for v1, v2, v3, v4 in zip(var1_values, var2_values, var3_values, var4_values)]\n",
    "\n",
    "\n",
    "\n",
    "# Create an empty NetworkX graph\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "\n",
    "\n",
    "# Add nodes to the graph\n",
    "\n",
    "G.add_nodes_from(nodes)\n",
    "\n",
    "\n",
    "\n",
    "# You can now further manipulate the graph by adding edges based on your desired relationships between nodes\n",
    "\n",
    "# For example, to add an edge between nodes based on a specific condition:\n",
    "\n",
    "# if needed logic to determine edge connections\n",
    "\n",
    "# G.add_edge(node1, node2)\n",
    "\n",
    "\n",
    "\n",
    "# Visualize the graph using a suitable plotting library (like matplotlib)\n",
    "\n",
    "nx.draw(G, with_labels=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514fc06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def create_network_graph_from_df(df):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Nodes from DataFrame columns\n",
    "    variables = df.columns.tolist()\n",
    "    G.add_nodes_from(variables)\n",
    "    \n",
    "    # Creating edges based on correlations\n",
    "    for i, col1 in enumerate(variables):\n",
    "        for j, col2 in enumerate(variables):\n",
    "            if i < j:  # Avoid self-loops and duplicate edges\n",
    "                G.add_edge(col1, col2)\n",
    "    \n",
    "    # Draw graph\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    pos = nx.spring_layout(G, seed=42)  # Layout for visualization\n",
    "    nx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='gray', node_size=3000, font_size=10)\n",
    "    plt.title(\"Network Analysis of DataFrame Variables\")\n",
    "    plt.show()\n",
    "\n",
    "# Run the function\n",
    "create_network_graph_from_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d67e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = nx.from_pandas_edgelist(df, \"node1\", \"node2\", \"node3\", \"node4\")\n",
    "G = nx.Graph(survived)\n",
    "\n",
    "# set a random seed and print the graph of heart dataset\n",
    "random.seed(42)\n",
    "nx.draw(survived, with_labels=True, node_color=\"steelblue\", node_size=600, font_weight='bold', \n",
    "        edge_color=\"black\", alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1fda7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c82f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52fce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Function to create network, compute centrality measures, and highlight key risk factors\n",
    "def analyze_centrality(df, gender):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Filter dataset by gender\n",
    "    df_gender = df[df[\"Gender\"] == gender].drop(columns=[\"Gender\"])\n",
    "    \n",
    "    # Compute correlation matrix\n",
    "    correlation_matrix = df_gender.corr()\n",
    "    \n",
    "    # Add nodes\n",
    "    variables = correlation_matrix.columns.tolist()\n",
    "    G.add_nodes_from(variables)\n",
    "    \n",
    "    # Add edges based on significant correlations\n",
    "    threshold = 0.3  # Define threshold for meaningful correlation\n",
    "    for i in range(len(variables)):\n",
    "        for j in range(i + 1, len(variables)):\n",
    "            var1, var2 = variables[i], variables[j]\n",
    "            correlation = correlation_matrix.loc[var1, var2]\n",
    "            if abs(correlation) > threshold:\n",
    "                G.add_edge(var1, var2, weight=correlation)\n",
    "\n",
    "    # Compute centrality measures\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=500)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    closeness_centrality = nx.closeness_centrality(G)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    centrality_df = pd.DataFrame({\n",
    "        \"Degree Centrality\": degree_centrality,\n",
    "        \"Eigenvector Centrality\": eigenvector_centrality,\n",
    "        \"Betweenness Centrality\": betweenness_centrality,\n",
    "        \"Closeness Centrality\": closeness_centrality\n",
    "    }).sort_values(by=\"Degree Centrality\", ascending=False)\n",
    "\n",
    "    # Identify top 3 influential risk factors for each centrality measure\n",
    "    top_factors = {\n",
    "        \"Degree Centrality\": centrality_df[\"Degree Centrality\"].nlargest(3).index.tolist(),\n",
    "        \"Eigenvector Centrality\": centrality_df[\"Eigenvector Centrality\"].nlargest(3).index.tolist(),\n",
    "        \"Betweenness Centrality\": centrality_df[\"Betweenness Centrality\"].nlargest(3).index.tolist(),\n",
    "        \"Closeness Centrality\": centrality_df[\"Closeness Centrality\"].nlargest(3).index.tolist()\n",
    "    }\n",
    "    \n",
    "    # Print the most influential risk factors\n",
    "    print(f\"\\nTop Influential Risk Factors for {gender}:\")\n",
    "    for measure, factors in top_factors.items():\n",
    "        print(f\"{measure}: {', '.join(factors)}\")\n",
    "    \n",
    "    # Draw the network\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    edges = G.edges(data=True)\n",
    "    weights = [abs(data['weight']) * 5 for _, _, data in edges]\n",
    "\n",
    "    nx.draw(G, pos, with_labels=True, node_color=\"lightblue\", edge_color=\"gray\",\n",
    "            node_size=3000, font_size=10, width=weights)\n",
    "    plt.title(f\"Network Analysis of CVD Risk Factors ({gender})\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Bar plot for centrality measures\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Assign colors to highlight top 3 influential factors\n",
    "    colors = [\"red\" if factor in sum(top_factors.values(), []) else \"gray\" for factor in centrality_df.index]\n",
    "    \n",
    "    centrality_df.plot(kind=\"bar\", figsize=(12, 6), colormap=\"viridis\", alpha=0.8, color=colors)\n",
    "    plt.title(f\"Centrality Measures for CVD Risk Factors ({gender})\")\n",
    "    plt.xlabel(\"Risk Factors\")\n",
    "    plt.ylabel(\"Centrality Score\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "# Run centrality analysis for Males and Females\n",
    "analyze_centrality(df, \"M\")\n",
    "analyze_centrality(df, \"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f04596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090337f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fd5922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Function to create network and compute centrality measures\n",
    "def analyze_centrality(df, gender):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Filter dataset by gender\n",
    "    df_gender = df[df[\"Gender\"] == gender].drop(columns=[\"Gender\"])\n",
    "    \n",
    "    # Compute correlation matrix\n",
    "    correlation_matrix = df_gender.corr()\n",
    "    \n",
    "    # Add nodes\n",
    "    variables = correlation_matrix.columns.tolist()\n",
    "    G.add_nodes_from(variables)\n",
    "    \n",
    "    # Add edges based on significant correlations\n",
    "    threshold = 0.3  # Define threshold for meaningful correlation\n",
    "    for i in range(len(variables)):\n",
    "        for j in range(i + 1, len(variables)):\n",
    "            var1, var2 = variables[i], variables[j]\n",
    "            correlation = correlation_matrix.loc[var1, var2]\n",
    "            if abs(correlation) > threshold:\n",
    "                G.add_edge(var1, var2, weight=correlation)\n",
    "\n",
    "    # Compute centrality measures\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=500)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    closeness_centrality = nx.closeness_centrality(G)\n",
    "    \n",
    "    # Convert to DataFrame for better visualization\n",
    "    centrality_df = pd.DataFrame({\n",
    "        \"Degree Centrality\": degree_centrality,\n",
    "        \"Eigenvector Centrality\": eigenvector_centrality,\n",
    "        \"Betweenness Centrality\": betweenness_centrality,\n",
    "        \"Closeness Centrality\": closeness_centrality\n",
    "    }).sort_values(by=\"Degree Centrality\", ascending=False)  # Sorting by Degree Centrality\n",
    "    \n",
    "    print(f\"\\nCentrality Measures for {gender}:\")\n",
    "    print(centrality_df)\n",
    "\n",
    "    # Draw the network\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    edges = G.edges(data=True)\n",
    "    weights = [abs(data['weight']) * 5 for _, _, data in edges]\n",
    "\n",
    "    nx.draw(G, pos, with_labels=True, node_color=\"lightblue\", edge_color=\"gray\",\n",
    "            node_size=3000, font_size=10, width=weights)\n",
    "    plt.title(f\"Network Analysis of CVD Risk Factors ({gender})\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualization of centrality measures\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    centrality_df.plot(kind=\"bar\", figsize=(12, 6), colormap=\"viridis\", alpha=0.8)\n",
    "    plt.title(f\"Centrality Measures for CVD Risk Factors ({gender})\")\n",
    "    plt.xlabel(\"Risk Factors\")\n",
    "    plt.ylabel(\"Centrality Score\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "# Run centrality analysis for Males and Females\n",
    "analyze_centrality(df, \"M\")\n",
    "analyze_centrality(df, \"F\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aeb2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224cd941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to create network and compute centrality measures\n",
    "def analyze_centrality(df, gender):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Filter dataset by gender\n",
    "    df_gender = df[df[\"Gender\"] == gender].drop(columns=[\"Gender\"])\n",
    "    \n",
    "    # Compute correlation matrix\n",
    "    correlation_matrix = df_gender.corr()\n",
    "    \n",
    "    # Add nodes\n",
    "    variables = correlation_matrix.columns.tolist()\n",
    "    G.add_nodes_from(variables)\n",
    "    \n",
    "    # Add edges based on significant correlations\n",
    "    threshold = 0.3  # Define threshold for meaningful correlation\n",
    "    for i in range(len(variables)):\n",
    "        for j in range(i + 1, len(variables)):\n",
    "            var1, var2 = variables[i], variables[j]\n",
    "            correlation = correlation_matrix.loc[var1, var2]\n",
    "            if abs(correlation) > threshold:\n",
    "                G.add_edge(var1, var2, weight=correlation)\n",
    "\n",
    "    # Compute centrality measures\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=500)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    closeness_centrality = nx.closeness_centrality(G)\n",
    "    \n",
    "    # Convert to DataFrame for better visualization\n",
    "    centrality_df = pd.DataFrame({\n",
    "        \"Degree Centrality\": degree_centrality,\n",
    "        \"Eigenvector Centrality\": eigenvector_centrality,\n",
    "        \"Betweenness Centrality\": betweenness_centrality,\n",
    "        \"Closeness Centrality\": closeness_centrality\n",
    "    }).sort_values(by=\"Degree Centrality\", ascending=False)  # Sorting by Degree Centrality\n",
    "    \n",
    "    print(f\"\\nCentrality Measures for {gender}:\")\n",
    "    print(centrality_df)\n",
    "\n",
    "    # Draw the network\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    edges = G.edges(data=True)\n",
    "    weights = [abs(data['weight']) * 5 for _, _, data in edges]\n",
    "\n",
    "    nx.draw(G, pos, with_labels=True, node_color=\"lightblue\", edge_color=\"gray\",\n",
    "            node_size=3000, font_size=10, width=weights)\n",
    "    plt.title(f\"Network Analysis of CVD Risk Factors ({gender})\")\n",
    "    plt.show()\n",
    "\n",
    "# Run centrality analysis for Males and Females\n",
    "analyze_centrality(df, \"M\")\n",
    "analyze_centrality(df, \"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be5f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9664f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Example DataFrame with 12 variables\n",
    "data = {\n",
    "    \"Cardiovascular Disease\": [1, 0, 1, 0, 1, 0, 1, 0],\n",
    "    \"Gender\": [\"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\"],\n",
    "    \"Weight\": [85, 65, 90, 55, 95, 60, 100, 70],\n",
    "    \"Height\": [180, 160, 175, 155, 185, 158, 190, 165],\n",
    "    \"Cholesterol\": [220, 180, 240, 170, 260, 190, 280, 200],\n",
    "    \"Blood Pressure\": [140, 120, 150, 115, 160, 125, 170, 130],\n",
    "    \"Diabetes\": [1, 0, 1, 0, 1, 0, 1, 0],\n",
    "    \"Smoking\": [1, 0, 1, 0, 1, 0, 1, 0],\n",
    "    \"Exercise\": [3, 5, 2, 6, 1, 7, 0, 8],\n",
    "    \"Age\": [60, 50, 65, 45, 70, 40, 75, 35],\n",
    "    \"BMI\": [27, 23, 29, 22, 31, 21, 33, 24],\n",
    "    \"Stress Level\": [7, 4, 8, 3, 9, 2, 10, 1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to create network graph\n",
    "def create_network_analysis(df, gender):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Filter dataset by gender\n",
    "    df_gender = df[df[\"Gender\"] == gender].drop(columns=[\"Gender\"])\n",
    "    \n",
    "    # Compute correlation matrix\n",
    "    correlation_matrix = df_gender.corr()\n",
    "    \n",
    "    # Add nodes (variables)\n",
    "    variables = correlation_matrix.columns.tolist()\n",
    "    G.add_nodes_from(variables)\n",
    "    \n",
    "    # Add edges (significant correlations)\n",
    "    threshold = 0.3  # Define threshold for meaningful correlation\n",
    "    for i in range(len(variables)):\n",
    "        for j in range(i + 1, len(variables)):\n",
    "            var1, var2 = variables[i], variables[j]\n",
    "            correlation = correlation_matrix.loc[var1, var2]\n",
    "            if abs(correlation) > threshold:\n",
    "                G.add_edge(var1, var2, weight=correlation)\n",
    "    \n",
    "    # Draw the network\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    edges = G.edges(data=True)\n",
    "    weights = [abs(data['weight']) * 5 for _, _, data in edges]\n",
    "    \n",
    "    nx.draw(G, pos, with_labels=True, node_color=\"lightblue\", edge_color=\"gray\",\n",
    "            node_size=3000, font_size=10, width=weights)\n",
    "    plt.title(f\"Network Analysis of CVD Risk Factors ({gender})\")\n",
    "    plt.show()\n",
    "\n",
    "# Generate networks for Males and Females\n",
    "create_network_analysis(df, \"M\")\n",
    "create_network_analysis(df, \"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc57073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66469d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3054fd21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f1319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# Create Network Graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add Nodes\n",
    "variables = df.columns.tolist()\n",
    "G.add_nodes_from(variables)\n",
    "\n",
    "# Add Edges based on correlation\n",
    "correlation_matrix = df.corr()\n",
    "threshold = 0.3  # Define threshold for significant correlation\n",
    "\n",
    "for i in range(len(variables)):\n",
    "    for j in range(i+1, len(variables)):\n",
    "        var1, var2 = variables[i], variables[j]\n",
    "        if var1 in correlation_matrix.columns and var2 in correlation_matrix.columns:\n",
    "            correlation = correlation_matrix.loc[var1, var2]\n",
    "            if abs(correlation) > threshold:  # Add edge if correlation is significant\n",
    "                G.add_edge(var1, var2, weight=correlation)\n",
    "\n",
    "# Draw the network\n",
    "plt.figure(figsize=(8, 6))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "edges = G.edges(data=True)\n",
    "weights = [abs(data['weight']) * 5 for _, _, data in edges]  # Scale edge thickness\n",
    "\n",
    "nx.draw(G, pos, with_labels=True, node_color=\"lightblue\", edge_color=\"gray\",\n",
    "        node_size=3000, font_size=10, width=weights)\n",
    "plt.title(\"Network Analysis of Cardiovascular Disease Risk\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f4bda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da4155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2d937b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
